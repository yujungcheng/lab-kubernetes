#### Ceph Storage

Use Ceph RBD for dynamic persistent volume with Cassandra.


#### Install Ceph CSI RBD plugin in Kubernetes cluster
Steps to deploy Ceph CSI RBD plugin in Kubernetes cluster.
To simplify steps, exist "client.admin" user key and "rbd" pool are used.
The Ceph cluster has only one monitor node which is 192.168.122.70

1. clone ceph-csi repo on master node (release-v3.6 branch)
    ```
    $ git clone --depth 1 --branch release-v3.6 https://github.com/ceph/ceph-csi.git
    Cloning into 'ceph-csi'...
    remote: Enumerating objects: 7613, done.
    remote: Counting objects: 100% (7613/7613), done.
    remote: Compressing objects: 100% (5506/5506), done.
    remote: Total 7613 (delta 2292), reused 4780 (delta 1636), pack-reused 0
    Receiving objects: 100% (7613/7613), 11.53 MiB | 6.02 MiB/s, done.
    Resolving deltas: 100% (2292/2292), done.
    $ cd ceph-csi/
    $ git branch
    * release-v3.6
    ```
2. get client.admin key and fsid from Ceph cluster
    ```
    $ sudo ceph auth get client.admin
    [sudo] password for ubuntu: 
    exported keyring for client.admin
    [client.admin]
    	key = AQCFW2FioDNLFhAAIHwffgelauUdN/QRpjeX4w==
    	caps mds = "allow *"
    	caps mgr = "allow *"
    	caps mon = "allow *"
    	caps osd = "allow *"
    
    $ sudo ceph mon dump
    dumped monmap epoch 1
    epoch 1
    fsid 3b544d34-c176-11ec-84d0-31c00678f807
    last_changed 2022-04-21T13:26:40.126776+0000
    created 2022-04-21T13:26:40.126776+0000
    min_mon_release 16 (pacific)
    election_strategy: 1
    0: [v2:192.168.122.70:3300/0,v1:192.168.122.70:6789/0] mon.admin
    ```
3. create new namespace for deploying ceph-csi
    ```
    $ kubectl create ns ceph-csi
    ```
4. enter to deploy/rbd/kubernetes directory in ceph-csi repo
    ```
    $ cd deploy/rbd/kubernetes/
    $ ls -l
    total 40
    -rw-rw-r-- 1 ubuntu ubuntu  309 Apr 27 15:30 csi-config-map.yaml
    -rw-rw-r-- 1 ubuntu ubuntu 1776 Apr 27 15:30 csi-nodeplugin-psp.yaml
    -rw-rw-r-- 1 ubuntu ubuntu 1110 Apr 27 15:30 csi-nodeplugin-rbac.yaml
    -rw-rw-r-- 1 ubuntu ubuntu 1199 Apr 27 15:30 csi-provisioner-psp.yaml
    -rw-rw-r-- 1 ubuntu ubuntu 3264 Apr 27 15:30 csi-provisioner-rbac.yaml
    -rw-rw-r-- 1 ubuntu ubuntu 7788 Apr 27 15:30 csi-rbdplugin-provisioner.yaml
    -rw-rw-r-- 1 ubuntu ubuntu 7252 Apr 27 15:30 csi-rbdplugin.yaml
    -rw-rw-r-- 1 ubuntu ubuntu  435 Apr 27 15:30 csidriver.yaml
    ```
5. create copy of the yaml files
    ```
    $ mkdir lab
    $ cp -afpR ./*.yaml ./lab
    $ cd ./lab
    ```
6. edit csi-config-map.yaml
    ```
    #
    # /!\ DO NOT MODIFY THIS FILE
    #
    # This file has been automatically generated by Ceph-CSI yamlgen.
    # The source for the contents can be found in the api/deploy directory, make
    # your modifications there.
    #
    ---
    apiVersion: v1
    kind: ConfigMap
    metadata:
      name: "ceph-csi-config"
    data:
      config.json: |-
        [
          {
            "clusterID": "3b544d34-c176-11ec-84d0-31c00678f807",
            "monitors": [
              "192.168.122.70:6789"
            ]
          }
        ]
    ```
7. create "csi-ceph-config.yaml" manifest file
    ```
    apiVersion: v1
    kind: ConfigMap
    data:
      ceph.conf: |
        [global]
        auth_cluster_required = cephx
        auth_service_required = cephx
        auth_client_required = cephx
      # keyring is a required key and its value should be empty
      keyring: |
    metadata:
      name: ceph-config
    ``` 
8. deploy the config map in ceph-csi namespace
    ```
    $ kubectl apply -n ceph-csi -f csi-config-map.yaml
    $ kubectl apply -n ceph-csi -f csi-ceph-config.yaml
    ```
9. create secret "csi-rbd-secret.yaml" to store key of "client.admin" user and deploy
    ```
    apiVersion: v1
    kind: Secret
    metadata:
      name: csi-rbd-secret
      namespace: ceph-csi
    stringData:
      userID: admin
      userKey: AQCFW2FioDNLFhAAIHwffgelauUdN/QRpjeX4w==
    ```
    ```
    $ kubectl apply -n ceph-csi -f csi-rbd-secret.yaml
    ```
10. update RBAC authorization yaml files.
change namespace from "default" to "ceph-csi"
    ```
    $ sed -i "s/namespace: default/namespace: ceph-csi/g" $(grep -rl "namespace: default" ./)
    ```
11. create ServiceAccount and RBAC ClusterRole/ClusterRoleBinding resources  
    ```
    $ kubectl create -f csi-provisioner-rbac.yaml
    $ kubectl create -f csi-nodeplugin-rbac.yaml
    ```
12. create PodSecurityPolicy
    ```
    $ kubectl create -f csi-provisioner-psp.yaml
    $ kubectl create -f csi-nodeplugin-psp.yaml
    ```
13. comment out "kms" config in csi-rbdplugin-provisioner.yaml and csi-rbdplugin.yaml
    ```
    # edit csi-rbdplugin-provisioner.yaml
    160             #- name: ceph-csi-encryption-kms-config
    161             #mountPath: /etc/ceph-csi-encryption-kms-config/
    
    230         #- name: ceph-csi-encryption-kms-config
    231         #  configMap:
    232         #    name: ceph-csi-encryption-kms-config
    
    # edit csi-rbdplugin.yaml
    107             #- name: ceph-csi-encryption-kms-config
    108             #  mountPath: /etc/ceph-csi-encryption-kms-config/
    
    188         #- name: ceph-csi-encryption-kms-config
    189         #  configMap:
    190         #    name: ceph-csi-encryption-kms-config
    ```
14. deploy rbdplugin-provisioner and rbdplugin
    ```
    $ kubectl apply -n ceph-csi -f csi-rbdplugin-provisioner.yaml
    $ kubectl apply -n ceph-csi -f csi-rbdplugin.yaml
    ```
15. create storage class for the ceph csi
    ```
    # "csi-storage-class.yaml" file
    apiVersion: storage.k8s.io/v1
    kind: StorageClass
    metadata:
       name: csi-rbd-sc
    provisioner: rbd.csi.ceph.com
    parameters:
       clusterID: 3b544d34-c176-11ec-84d0-31c00678f807
       pool: rbd
       imageFeatures: layering
       csi.storage.k8s.io/provisioner-secret-name: csi-rbd-secret
       csi.storage.k8s.io/provisioner-secret-namespace: ceph-csi
       csi.storage.k8s.io/controller-expand-secret-name: csi-rbd-secret
       csi.storage.k8s.io/controller-expand-secret-namespace: ceph-csi
       csi.storage.k8s.io/node-stage-secret-name: csi-rbd-secret
       csi.storage.k8s.io/node-stage-secret-namespace: ceph-csi
       csi.storage.k8s.io/fstype: ext4
    reclaimPolicy: Delete
    allowVolumeExpansion: true
    mountOptions:
       - discard
    ```
    ```
    $ kubectl apply -f csi-storage-class.yaml
    ```
16. check pods in ceph-csi namespace are running
    ```
    $ kubectl get pod -n ceph-csi
    NAME                                         READY   STATUS    RESTARTS      AGE
    csi-rbdplugin-7r9sk                          3/3     Running   0             3d14h
    csi-rbdplugin-j2j4d                          3/3     Running   0             3d14h
    csi-rbdplugin-provisioner-7774f66f95-22k6t   7/7     Running   6 (16h ago)   3d14h
    csi-rbdplugin-provisioner-7774f66f95-7jgs5   7/7     Running   6 (16h ago)   3d14h
    csi-rbdplugin-provisioner-7774f66f95-bcj6f   7/7     Running   3 (16h ago)   3d14h
    csi-rbdplugin-x5bbg                          3/3     Running   0             3d14h
    ```
17. create PVC for testing
    ```
    # "csi-pvc-test.yaml"
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      name: rbd-pvc-test
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 1Gi
      storageClassName: csi-rbd-sc
    ```
    ```
    $ kubectl apply -f csi-pvc-test.yaml 
    persistentvolumeclaim/rbd-pvc-test created
    
    $ kubectl get pvc rbd-pvc-test
    NAME           STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
    rbd-pvc-test   Bound    pvc-8ffa2097-22fe-4329-8061-5fc817b596e5   1Gi        RWO            csi-rbd-sc     31s
    
    $ kubectl get pv pvc-8ffa2097-22fe-4329-8061-5fc817b596e5
    NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                  STORAGECLASS   REASON   AGE
    pvc-8ffa2097-22fe-4329-8061-5fc817b596e5   1Gi        RWO            Delete           Bound    default/rbd-pvc-test   csi-rbd-sc              40s
    
    $ kubectl describe pv pvc-8ffa2097-22fe-4329-8061-5fc817b596e5
    Name:            pvc-8ffa2097-22fe-4329-8061-5fc817b596e5
    Labels:          <none>
    Annotations:     pv.kubernetes.io/provisioned-by: rbd.csi.ceph.com
    Finalizers:      [kubernetes.io/pv-protection]
    StorageClass:    csi-rbd-sc
    Status:          Bound
    Claim:           default/rbd-pvc-test
    Reclaim Policy:  Delete
    Access Modes:    RWO
    VolumeMode:      Filesystem
    Capacity:        1Gi
    Node Affinity:   <none>
    Message:         
    Source:
        Type:              CSI (a Container Storage Interface (CSI) volume source)
        Driver:            rbd.csi.ceph.com
        FSType:            ext4
        VolumeHandle:      0001-0024-3b544d34-c176-11ec-84d0-31c00678f807-0000000000000001-ac0a4f97-c5f6-11ec-ab33-ae001d6e8334
        ReadOnly:          false
        VolumeAttributes:      clusterID=3b544d34-c176-11ec-84d0-31c00678f807
                               imageFeatures=layering
                               imageName=csi-vol-ac0a4f97-c5f6-11ec-ab33-ae001d6e8334
                               journalPool=rbd
                               pool=rbd
                               storage.kubernetes.io/csiProvisionerIdentity=1650808874374-8081-rbd.csi.ceph.com
    Events:                <none>
    ```
    ```
    # check rbd in ceph cluster
    $ rbd info csi-vol-ac0a4f97-c5f6-11ec-ab33-ae001d6e8334
    rbd image 'csi-vol-ac0a4f97-c5f6-11ec-ab33-ae001d6e8334':
    	size 1 GiB in 256 objects
    	order 22 (4 MiB objects)
    	snapshot_count: 0
    	id: 60632cb5285a
    	block_name_prefix: rbd_data.60632cb5285a
    	format: 2
    	features: layering
    	op_features: 
    	flags: 
    	create_timestamp: Wed Apr 27 16:52:59 2022
    	access_timestamp: Wed Apr 27 16:52:59 2022
    	modify_timestamp: Wed Apr 27 16:52:59 2022
    ```
    ```
    # delete the PVC
    $ kubectl delete -f csi-pvc-test.yaml 
    persistentvolumeclaim "rbd-pvc-test" deleted
    ```

#### test result
```
$ kubectl get statefulset cassandra
NAME        READY   AGE
cassandra   3/3     12m

$ kubectl get pvc -o wide | grep cassandra
NAME                         STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS          AGE   VOLUMEMODE
cassandra-data-cassandra-0   Bound    pvc-caa4c7f2-a08e-4c49-8e6d-831b088298fb   1Gi        RWO            csi-rbd-sc            13m   Filesystem
cassandra-data-cassandra-1   Bound    pvc-99e35a77-923a-412a-bed1-8133e43aeb7c   1Gi        RWO            csi-rbd-sc            13m   Filesystem
cassandra-data-cassandra-2   Bound    pvc-65e58a45-17ce-4191-86eb-fe2957154708   1Gi        RWO            csi-rbd-sc            12m   Filesystem

$ kubectl get pv -o wide | grep cassandra
NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                                STORAGECLASS          REASON   AGE   VOLUMEMODE
pvc-65e58a45-17ce-4191-86eb-fe2957154708   1Gi        RWO            Delete           Bound    default/cassandra-data-cassandra-2   csi-rbd-sc                     13m   Filesystem
pvc-99e35a77-923a-412a-bed1-8133e43aeb7c   1Gi        RWO            Delete           Bound    default/cassandra-data-cassandra-1   csi-rbd-sc                     14m   Filesystem
pvc-caa4c7f2-a08e-4c49-8e6d-831b088298fb   1Gi        RWO            Delete           Bound    default/cassandra-data-cassandra-0   csi-rbd-sc                     14m   Filesystem

# check ceph rbd list
$ sudo rbd ls -l
[sudo] password for ubuntu: 
NAME                                          SIZE   PARENT  FMT  PROT  LOCK
csi-vol-05bc43e7-c49a-11ec-b8f2-f2a82c0bebdf  1 GiB            2            
csi-vol-278d3561-c49a-11ec-b8f2-f2a82c0bebdf  1 GiB            2            
csi-vol-ff699b9d-c499-11ec-b8f2-f2a82c0bebdf  1 GiB            2 
```

#### reference
https://computingforgeeks.com/persistent-storage-for-kubernetes-with-ceph-rbd/
https://www.gushiciku.cn/pl/ptAi/zh-tw
https://github.com/kubernetes/examples/tree/master/volumes

> Kubernetes CSI
https://kubernetes.io/blog/2019/01/15/container-storage-interface-ga/
https://github.com/kubernetes-csi
https://kubernetes-csi.github.io/
https://kubernetes-csi.github.io/docs/

> Issue with supporting Ceph RBD in Kubernetes.
https://github.com/kubernetes/kubernetes/issues/71904
https://github.com/rootsongjc/kubernetes-handbook/issues/73
https://github.com/kubernetes/kubernetes/issues/85454
https://github.com/kubernetes/kubernetes/pull/95361

> Ceph CSI
https://github.com/ceph/ceph-csi/
https://github.com/ceph/ceph-csi/blob/devel/docs/deploy-rbd.md


> Cassandra
http://pwittrock.github.io/docs/tutorials/stateful-application/cassandra/
https://kubernetes.io/docs/tutorials/stateful-application/cassandra/